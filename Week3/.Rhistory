x = c(6,4,3)
y = c(5,3,7)
z = c(9,3,4)
test = matrix(c(x,y,z), byrow = FALSE, nrow = 3, dimnames = list(c(1,2,3),c('x','y','z')) )
test
x <- c(4,5,1)
barplot(x)
x <- c(4,5,1)
names(x) <- c("1","2","3")
barplot(x)
x <- c(4,5,1)
names(x) <- c("1","2","3")
plot(x)
View(test)
countour(test)
x = c(6,4,3)
y = c(5,3,7)
z = c(9,3,4)
test = matrix(c(x,y,z), byrow = FALSE, nrow = 3, dimnames = list(c(1,2,3),c('x','y','z')) )
contour(test)
persp(test)
persp(test, expand 0.2)
persp(test, expand=0.2)
persp(volcano, expand=0.2)
movie_date_likes <- subset(movie_data_sorted, movie_data_sorted$cast_total_facebook_likes == 0 || movie_data_sorted$movie_facebook_likes == 0)
#In the first part of this homework assignment, you will load in a dataframe, clean it up, and get practice manipulating it. In the second part, you will get practice calculating measures of fit/dispersion. Please remember to work on this with your partner and submit a single assignment to Blackboard; one grade will be given to both partners. This is due next week on Thursday at 10h before lecture.
#Part 1: Dataframe clean up and practice
#1 Load in the dataframe "movie_metadata.csv" (Note that the separator used in this file is the tab which is indicated with "\t")
rm(list=ls(all=TRUE))
setwd("~/Documents/RU/Sem2/Statistics/Week3")
movie_data <- read.table(file = "movie_metadata.csv", header=TRUE, sep="\t", quote="", comment.char="", fill=TRUE)
#2 View a summary of the contents of this dataframe.
str(movie_data)
#3 how many NAs are there in the budget column? look up help on the is.na() function in order to figure out how to determine this.
length(is.na(movie_data$budget)) #(COUNT TRUE)
#4 create a subset of the dataframe that only includes those rows that are not missing any data. Use this subset from now on.
movie_data_complete <- subset(movie_data, complete.cases(movie_data))
#5 for the imdb_score and aspect_ratio columns, replace the commas with dots as the decimal indicator.
movie_data_complete$imdb_score <- gsub(",", ".", movie_data_complete$imdb_score)
movie_data_complete$aspect_ratio <- gsub(",", ".", movie_data_complete$aspect_ratio)
#6 now convert these columns to numeric values (see practical activity for hint on how to do this)
movie_data_complete$imdb_score <- as.numeric(movie_data_complete$imdb_score)
movie_data_complete$aspect_ratio <- as.numeric(movie_data_complete$aspect_ratio)
#7 round the aspect_ratio values to 1 decimal place
movie_data_complete$aspect_ratio <- round(movie_data_complete$aspect_ratio,digits = 1)
#8 sort the dataframe by country, then decreasing by gross (gross refers to the amount of revenue generated by the movie). Use this sorted version in the next questions.
movie_data_sorted <- movie_data_complete[order(movie_data_complete$country,-movie_data_complete$gross),]
#9 The row names (which, here, are numbers) are out of order. Replace them with new continuous numbering from 1 to the end of the dataframe.
rownames(movie_data_sorted) <- 1:nrow(movie_data_sorted)
#10 Remove the column movie_imdb_link
movie_data_sorted$movie_imdb_link <- NULL
#11 Create a new column that adds together the values from the cast_total_facebook_likes and the movie_facebook_likes. call this column "total_facebook_likes"
movie_data_sorted$total_facebook_likes <- movie_data_sorted$cast_total_facebook_likes + movie_data_sorted$movie_facebook_likes
#12 Create a subset of all rows that contain 0 likes in at least one of the facebook like-related columns.
movie_date_likes <- subset(movie_data_sorted, movie_data_sorted$cast_total_facebook_likes == 0 || movie_data_sorted$movie_facebook_likes == 0)
View(movie_date_likes)
View(movie_data_sorted)
View(movie_date_likes)
movie_date_likes <- subset(movie_data_sorted, movie_data_sorted$cast_total_facebook_likes == 0 | movie_data_sorted$movie_facebook_likes == 0)
View(movie_date_likes)
write.table(movie_data_sorted, "cleaned_movie_data.csv", quote=FALSE, sep="\t", row.names=FALSE)
vector <- movie_data$imdb_score
vector_mean <- mean(vector)
vector_error <- vector_mean - vector
x <- movie_data$imdb_score
x_mean <- mean(vector)
x_error <- x_mean - x
help(mean)
#1 Sum of squared errors:
x <- movie_data$imdb_score
x <- subset(x, complete.cases(x))
x_mean <- mean(vector)
x_error <- x_mean - x
x <- movie_data$imdb_score
x <- subset(x, complete.cases(x))
x
x_mean <- mean(vector)
x <- as.numeric(x)
x_mean <- mean(vector)
x_mean <- mean(x)
x_error <- x_mean - x
x <- movie_data$imdb_score
x <- subset(x, complete.cases(x))
x <- as.numeric(x)
x_mean <- mean(x)
x_error <- x_mean - x
x_squared <- x_error^2
SS <- sum(x_squared)
install.packages("plotrix")
library("plotrix", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.3")
#In the first part of this homework assignment, you will load in a dataframe, clean it up, and get practice manipulating it. In the second part, you will get practice calculating measures of fit/dispersion. Please remember to work on this with your partner and submit a single assignment to Blackboard; one grade will be given to both partners. This is due next week on Thursday at 10h before lecture.
#Part 1: Dataframe clean up and practice
#1 Load in the dataframe "movie_metadata.csv" (Note that the separator used in this file is the tab which is indicated with "\t")
rm(list=ls(all=TRUE))
setwd("~/Documents/RU/Sem2/Statistics/Week3")
movie_data <- read.table(file = "movie_metadata.csv", header=TRUE, sep="\t", quote="", comment.char="", fill=TRUE)
#2 View a summary of the contents of this dataframe.
str(movie_data)
#3 how many NAs are there in the budget column? look up help on the is.na() function in order to figure out how to determine this.
length(is.na(movie_data$budget)) #(COUNT TRUE)
#4 create a subset of the dataframe that only includes those rows that are not missing any data. Use this subset from now on.
movie_data_complete <- subset(movie_data, complete.cases(movie_data))
#5 for the imdb_score and aspect_ratio columns, replace the commas with dots as the decimal indicator.
movie_data_complete$imdb_score <- gsub(",", ".", movie_data_complete$imdb_score)
movie_data_complete$aspect_ratio <- gsub(",", ".", movie_data_complete$aspect_ratio)
#6 now convert these columns to numeric values (see practical activity for hint on how to do this)
movie_data_complete$imdb_score <- as.numeric(movie_data_complete$imdb_score)
movie_data_complete$aspect_ratio <- as.numeric(movie_data_complete$aspect_ratio)
#7 round the aspect_ratio values to 1 decimal place
movie_data_complete$aspect_ratio <- round(movie_data_complete$aspect_ratio,digits = 1)
#8 sort the dataframe by country, then decreasing by gross (gross refers to the amount of revenue generated by the movie). Use this sorted version in the next questions.
movie_data_sorted <- movie_data_complete[order(movie_data_complete$country,-movie_data_complete$gross),]
#9 The row names (which, here, are numbers) are out of order. Replace them with new continuous numbering from 1 to the end of the dataframe.
rownames(movie_data_sorted) <- 1:nrow(movie_data_sorted)
#10 Remove the column movie_imdb_link
movie_data_sorted$movie_imdb_link <- NULL
#11 Create a new column that adds together the values from the cast_total_facebook_likes and the movie_facebook_likes. call this column "total_facebook_likes"
movie_data_sorted$total_facebook_likes <- movie_data_sorted$cast_total_facebook_likes + movie_data_sorted$movie_facebook_likes
#12 Create a subset of all rows that contain 0 likes in at least one of the facebook like-related columns.
movie_date_likes <- subset(movie_data_sorted, movie_data_sorted$cast_total_facebook_likes == 0 | movie_data_sorted$movie_facebook_likes == 0)
#13 Save the dataframe (not the subset you just created in 12!) to the file "cleaned_movie_data.csv"  Don't include row names in the saved file
write.table(movie_data_sorted, "cleaned_movie_data.csv", quote=FALSE, sep="\t", row.names=FALSE)
#Part 2: For the data in the imdb_score column, manually calculate the:
#1 Sum of squared errors:
x <- movie_data$imdb_score
x <- subset(x, complete.cases(x))
x <- as.numeric(x)
x_mean <- mean(x)
x_error <- x_mean - x
x_squared <- x_error^2
SS <- sum(x_squared)
#2 The variance:
variance <- SS/(length(x_squared)-1)
#3 The standard deviation:
standard_dev <-sqrt(variance)
#4 The standard error:
standard_err <- standard_dev/sqrt(length(x_squared))
#5 Now verify that your calculation of the standard deviation is correct by using the sd() function.
sd(x)
#6 Now verfy that your calculation of the standard error is correct. To do this, you will need to install and load the package called "plotrix." Then, you can use the function std.error()
std.error(x)
standard_dev
standard_err
